---
title: "Why we don't benchmark"
description: "Our approach prioritizes enduring guidance from frontier labs over empirical validation with today's models."
---

We don't validate whether XML-tagged prompts outperform pure Markdown empirically. Here's why:

Our goal is **enduring guidance**â€”advice that remains valid as models improve. The only durable foundation is what frontier labs recommend, which also reflects what they use in training.

Empirical validation with today's SOTA models would mean making decisions about the future based on the past. When Anthropic, OpenAI, or Google update their guidance, we update ours.
